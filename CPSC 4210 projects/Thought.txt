Parallel computation with multicore and multithreading is one of the most important studies for Computer Science student who want to learn more about High Performance Computing. There are many considerations for programmers when trying to improve the efficiency of a program with parallel computation. Programers have to optimize the code to be cache friendly before implement parallel computation. Example with Matrix-matrix Multiplication (MM) was with loop rearrangement for spatial locality and blocking implementation for temporal locality. 
When implement OpenMP, we have many choices of strategy to choose, including number of threads, type of thread scheduling (static, dynamic, and guided), the chunk size for each thread for starter in order to create an efficient multithreaded parallel program. Bigger number of threads is not always better, choose threading scheduling based on what the program’ purpose, what chunk size to choose as larger chunk should be more efficient than smaller chunk.
However, parallel computation should only implement with large data set to be a good trade off. In this project, serial computation is good enough with small data size as the multithreading computation of OpenMP did not offer a good trade off in comparison. However, as the data size increase OpenMP and CUDA offer a more efficient in executing the program. Personally, we should OpenMP used first, then CUDA should be used when you see a slow down in improvement in OpenMP. The exceptions are to use CUDA where a program involve lot of simple calculations and OpenMP where the program involve complicated calculations.